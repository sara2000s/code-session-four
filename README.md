# ğŸ“¦ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

# ğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
file_path = 'path/to/dataset.csv'  # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯
data = pd.read_csv(file_path)

# ğŸ“ 1. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ù…Ø´Ø¯Ù‡
print("ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡:")
print(data.isnull().sum())

# ğŸš® 2. Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ù…Ø´Ø¯Ù‡
data = data.dropna()
print("\nâœ… Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ù…Ø´Ø¯Ù‡:")
print(data.info())

# ğŸš« 3. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± (Ù…Ø«Ù„ Ø§Ø¹Ø¯Ø§Ø¯ Ù…Ù†ÙÛŒ Ø¯Ø± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ù…Ù†Ø·Ù‚ÛŒ)
invalid_rows = data[(data < 0).any(axis=1)]
print("\nğŸš¨ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø±:")
print(invalid_rows)

# ğŸ—‘ï¸ 4. Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±
data = data[(data >= 0).all(axis=1)]
print("\nâœ… Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±:")
print(data.info())

# ğŸ“Š 5. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Min-Max Scaler
scaler = MinMaxScaler()

# ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø±Ø§ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
numeric_cols = data.select_dtypes(include=[np.number]).columns
data[numeric_cols] = scaler.fit_transform(data[numeric_cols])

print("\nğŸ“ Ù¾Ø³ Ø§Ø² Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
print(data.head())

# ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
cleaned_file_path = 'cleaned_normalized_dataset.csv'
data.to_csv(cleaned_file_path, index=False)
print(f"\nâœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ '{cleaned_file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
